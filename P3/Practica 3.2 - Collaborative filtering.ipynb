{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grado en ciencia de datos - Big Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3.2- Sistemas de recomendación con collaborative filtering\n",
    "\n",
    "En esta práctica afrontaremos vamos a crear un sistema de recomendación de películas con la librería de Spark MLib.\n",
    "\n",
    "Ten en cuenta que una vez tengas en marcha Spark, podrás visualizar la evolución de cada trabajo de Spark en  <http://localhost:4040>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción de la puntuación a películas\n",
    "\n",
    "En esta práctica vamos a intentar predecir lo que quieren los usuarios de manera similar a lo que hacen Amazon o Netflix para recomendar los productos o las películas en las que puedes estar interesado. En este caso, vamos a usar Spark para montar un sistema de recomendación que permita recomendar películas a un usuario. Para ello utilizaremos el modelo de filtro colaborativo con el algoritmo Alternating Least Squares (ALS) disponible en Spark MLlib ([sparkml]).\n",
    "\n",
    "Como conjunto de datos utilizaremos [MovieLens](http://grouplens.org/datasets/movielens/) que contiene 20 millones de puntuaciones de usuarios a películas. Descomprime el fichero ml-20m.zip en tu carpeta de datos. Dentro de esta carpeta debe estar la carpeta ml-20m con todos los csv's incluidos en el fichero zip.\n",
    "\n",
    "La práctica está dividida en cuatro partes:\n",
    "* *Parte 0*: Preliminares\n",
    "* *Parte 1*: Recomendaciones básicas\n",
    "* *Parte 2*: Filtro colaborativo\n",
    "* *Parte 3*: Predicciones para ti\n",
    "\n",
    "Como ya hemos comentado en las prácticas anteriores, cuidado antes de usar `collect()` ya que el dataset con el que trabajamos es bastante grande.\n",
    "\n",
    "[sparkml]: http://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName(\"Ejemplo pySparkSQL\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"file:///D:/tmp/spark-warehouse\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otros imports necesarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "from pyspark.sql import Row\n",
    "from test_helper import Test\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notas\n",
    "\n",
    "En la práctica solo es necesario usar instrucciones básicas de python y las transformaciones y acciones de DataFrames.\n",
    "\n",
    "**Ejecutar la siguiente celda:** Establecemos los nombres de los ficheros a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from test_helper import Test\n",
    "\n",
    "dbfs_dir = './datos/ml-20m'\n",
    "movies_filename = dbfs_dir + '/movies.csv'\n",
    "ratings_filename = dbfs_dir + '/ratings.csv'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Preliminarres\n",
    "\n",
    "Leemos los dos ficheros como DataFrames.\n",
    "\n",
    "El conjunto de datos consiste en varios ficheros CSV con sus cabeceras, por lo que podemos parsearslos fácilmente con Spark.\n",
    "\n",
    "De todos los ficheros disponibles, solo nos interesan dos: ratings.csv y movies.csv. El primero almacena en cada fila la puntuación de un usuario a una película, mientras que el segundo almacena en cada fila la información de una película. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ficheros en la carpeta: ['genome-scores.csv', 'genome-tags.csv', 'links.csv', 'movies.csv', 'ratings.csv', 'README.txt', 'tags.csv']\n"
     ]
    }
   ],
   "source": [
    "print('Ficheros en la carpeta:', os.listdir(dbfs_dir))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que conocemos el esquema de los ficheros, lo vamos a especificar explícitamente para acelerar la lectura y que Spark no tenga que leer dos veces cada fichero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "ratings_df_schema = StructType([\n",
    "  StructField(\"userId\", IntegerType(), True),\n",
    "  StructField(\"movieId\", IntegerType(), True),\n",
    "  StructField(\"rating\", FloatType(), True)\n",
    "])\n",
    "    \n",
    "movies_df_schema = StructType([\n",
    "  StructField(\"ID\", IntegerType(), True),\n",
    "  StructField(\"title\", StringType(), True)\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargamos los datos y los cacheamos\n",
    "\n",
    "**Paciencia**: La lectura puede tardar un poco..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 20000263 puntuaciones y 27278 películas en el conjunto de datos\n",
      "Puntuaciones:\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      2|   3.5|\n",
      "|     1|     29|   3.5|\n",
      "|     1|     32|   3.5|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Películas:\n",
      "+---+-----------------------+\n",
      "|ID |title                  |\n",
      "+---+-----------------------+\n",
      "|1  |Toy Story (1995)       |\n",
      "|2  |Jumanji (1995)         |\n",
      "|3  |Grumpier Old Men (1995)|\n",
      "+---+-----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "# Leemos el csv de ratings, con header\n",
    "raw_ratings_df = spark.read.csv(ratings_filename, header=True, schema=ratings_df_schema)\n",
    "\n",
    "# Leemos el csv de movies, con header\n",
    "raw_movies_df = spark.read.csv(movies_filename, header=True, schema=movies_df_schema)\n",
    "\n",
    "# Eliminamos las columnas que no interesan\n",
    "ratings_df = raw_ratings_df   # Nos interesan todas.\n",
    "movies_df = raw_movies_df.select('ID', 'title')\n",
    "\n",
    "# Cacheamos los DataFrames ¡¡¡CUIADADO CON EL LABORATORIO!!!!\n",
    "ratings_df.cache()\n",
    "movies_df.cache()\n",
    "\n",
    "# Comprobamos si se han cacheado correctamente.\n",
    "assert ratings_df.is_cached\n",
    "assert movies_df.is_cached\n",
    "\n",
    "# Contamos el número de elementos en cada DataFrame para forzar la lectura y el cacheo\n",
    "raw_ratings_count = raw_ratings_df.count()\n",
    "ratings_count = ratings_df.count()\n",
    "raw_movies_count = raw_movies_df.count()\n",
    "movies_count = movies_df.count()\n",
    "\n",
    "print('Hay %s puntuaciones y %s películas en el conjunto de datos' % (ratings_count, movies_count))\n",
    "print('Puntuaciones:')\n",
    "ratings_df.show(3)\n",
    "\n",
    "print('Películas:')\n",
    "movies_df.show(3, truncate=False)\n",
    "\n",
    "assert raw_ratings_count == ratings_count\n",
    "assert raw_movies_count == movies_count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificamos que todo esté correcto, no debería dar ningún error la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ratings_count == 20000263\n",
    "assert movies_count == 27278\n",
    "assert movies_df.filter(movies_df.title == 'Toy Story (1995)').count() == 1\n",
    "assert ratings_df.filter((ratings_df.userId == 6) & (ratings_df.movieId == 1) & (ratings_df.rating == 5.0)).count() == 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a revisar como son los DataFrames que acabamos de leer.\n",
    "\n",
    "**Ejecutar las siguientes celdas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------------------------+\n",
      "|ID |title                             |\n",
      "+---+----------------------------------+\n",
      "|1  |Toy Story (1995)                  |\n",
      "|2  |Jumanji (1995)                    |\n",
      "|3  |Grumpier Old Men (1995)           |\n",
      "|4  |Waiting to Exhale (1995)          |\n",
      "|5  |Father of the Bride Part II (1995)|\n",
      "+---+----------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      2|   3.5|\n",
      "|     1|     29|   3.5|\n",
      "|     1|     32|   3.5|\n",
      "|     1|     47|   3.5|\n",
      "|     1|     50|   3.5|\n",
      "+------+-------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ratings_df.show(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Recomendaciones básicas\n",
    "\n",
    "Antes de utilizar el filtro colaborativo vamos a realizar unas recomendaciones más simples, basadas en las estadísticas globales. Veremos que la ventaja del filtro colaborativo es que en vez de realizar la misma recomendación a todos los usuarios como haríamos aquí, realizamos recomendaciones personalizadas.\n",
    "\n",
    "Vamos a por la forma simple de recomendación: La forma más simple consiste en recomendar la película con la mejor puntuación media.\n",
    "\n",
    "Usaremos Spark para encontrar el nombre, el número de puntuaciones y la media de las puntuaciones de las 20 películas con la media más alta de puntuación y que tengan al menos 500 puntuaciones. Eliminamos las puntuaciones con menos de 500 puntuaciones ya que es posible que estas no sean del gusto de todo el mundo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1a) Películas con la media de puntuación más alta\n",
    "\n",
    "Estos son los pasos que debes seguir:\n",
    "\n",
    "1. `ratings_df` contiene tres columnas:\n",
    "    - userID: El ID del usuario que ha dado la puntuación\n",
    "    - movieID: El ID de la película puntuada\n",
    "    - rating: la puntuación.\n",
    "\n",
    "   Primero, transforma `ratings_df` en un segundo DataFrame, `movie_ids_with_avg_ratings` con las siguientes columnas:\n",
    "    - El ID de la película\n",
    "    - El número de puntuaciones recibidas por la película\n",
    "    - La media de las puntuaciones recibidas por la película\n",
    "   Para ello considera el uso de GroupBy, junto con agg y las funciones count y avg.\n",
    "\n",
    "2. Transforma `movie_ids_with_avg_ratings` a otro DataFrame, `movie_names_with_avg_ratings_df` que añade el título de la película acada fila. `movie_names_with_avg_ratings_df` contendrá las siguientes columnas:\n",
    "    - El ID de la película\n",
    "    - El título de la película\n",
    "    - El número de puntuaciones recibidas por la película\n",
    "    - La media de las puntuaciones recibidas por la película\n",
    "\n",
    "   **Nota**: Considera el uso de join para unir el DataFrame `movie_ids_with_avg_ratings` y el de las películas `movies_df`\n",
    "\n",
    "El resultado debería ser similar al siguiente:\n",
    "```\n",
    "movie_ids_with_avg_ratings_df:\n",
    "+-------+-----+------------------+\n",
    "|movieId|count|average           |\n",
    "+-------+-----+------------------+\n",
    "|1831   |7463 |2.5785207021305103|\n",
    "|431    |8946 |3.695059244355019 |\n",
    "|631    |2193 |2.7273141814865483|\n",
    "+-------+-----+------------------+\n",
    "only showing top 3 rows\n",
    "\n",
    "movie_names_with_avg_ratings_df:\n",
    "+-------+-----------------------------+-----+-------+\n",
    "|average|title                        |count|movieId|\n",
    "+-------+-----------------------------+-----+-------+\n",
    "|5.0    |Ella Lola, a la Trilby (1898)|1    |94431  |\n",
    "|5.0    |Serving Life (2011)          |1    |129034 |\n",
    "|5.0    |Diplomatic Immunity (2009? ) |1    |107434 |\n",
    "+-------+-----------------------------+-----+-------+\n",
    "only showing top 3 rows\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_ids_with_avg_ratings_df:\n",
      "+-------+-----+------------------+-------+\n",
      "|movieId|count|average           |MovieID|\n",
      "+-------+-----+------------------+-------+\n",
      "|3997   |2047 |2.0703468490473864|3997   |\n",
      "|1580   |35580|3.55831928049466  |1580   |\n",
      "|3918   |1246 |2.918940609951846 |3918   |\n",
      "+-------+-----+------------------+-------+\n",
      "only showing top 3 rows\n",
      "\n",
      "movie_names_with_avg_ratings_df:\n",
      "+-------+-----+------------------+-------+--------------------------------+\n",
      "|movieId|count|average           |MovieID|title                           |\n",
      "+-------+-----+------------------+-------+--------------------------------+\n",
      "|3997   |2047 |2.0703468490473864|3997   |Dungeons & Dragons (2000)       |\n",
      "|1580   |35580|3.55831928049466  |1580   |Men in Black (a.k.a. MIB) (1997)|\n",
      "|3918   |1246 |2.918940609951846 |3918   |Hellbound: Hellraiser II (1988) |\n",
      "+-------+-----+------------------+-------+--------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions\n",
    "\n",
    "# A partir de ratingsDF, crear movie_ids_with_avg_ratings_df donde tengamos \n",
    "# para cada película el conteo de puntuaciones y la media de las mismas\n",
    "movie_ids_with_avg_ratings_df = (\n",
    "    ratings_df.groupBy('movieId')\n",
    "              .agg(functions.count('*').alias('count'),\n",
    "                   functions.avg('rating').alias('average'))\n",
    "              .withColumn('MovieID', functions.col('movieId'))\n",
    "              .select('movieId', 'count', 'average', 'MovieID')\n",
    ")\n",
    "print('movie_ids_with_avg_ratings_df:')\n",
    "movie_ids_with_avg_ratings_df.show(3, truncate=False)\n",
    "\n",
    "# Nota: movie_names_df es una variable temporal, la usaremos para guardar la unión del DataFrame que\n",
    "# acabamos de obtener y el DataFrame movies_df (la unión se debe realizar por los campos movieId e ID)\n",
    "movie_names_df = movie_ids_with_avg_ratings_df.join(\n",
    "    movies_df,\n",
    "    movie_ids_with_avg_ratings_df.movieId == movies_df.ID,\n",
    "    'inner'\n",
    ")\n",
    "\n",
    "# En este segundo paso, eliminar el atributo ID de movie_names usando drop\n",
    "movie_names_with_avg_ratings_df = movie_names_df.drop('ID')\n",
    "print('movie_names_with_avg_ratings_df:')\n",
    "movie_names_with_avg_ratings_df.show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertEquals(movie_ids_with_avg_ratings_df.count(), 26744,\n",
    "                'movie_ids_with_avg_ratings_df.count() incorrecto (se esperaban 26744)')\n",
    "movie_ids_with_ratings_take_ordered = movie_ids_with_avg_ratings_df.orderBy('MovieID').take(3)\n",
    "_take_0 = movie_ids_with_ratings_take_ordered[0]\n",
    "_take_1 = movie_ids_with_ratings_take_ordered[1]\n",
    "_take_2 = movie_ids_with_ratings_take_ordered[2]\n",
    "Test.assertTrue(_take_0[0] == 1 and _take_0[1] == 49695,\n",
    "                'Conteo de puntuaciones incorrecto para la película {0} (se esperaban 49695)'.format(_take_0[0]))\n",
    "Test.assertEquals(__builtin__.round(_take_0[2], 2), 3.92, \"Puntuación media incorecta para la película {0}. Se esperaba 3.92\".format(_take_0[0]))\n",
    "\n",
    "Test.assertTrue(_take_1[0] == 2 and _take_1[1] == 22243,\n",
    "                'Conteo de puntuaciones incorrecto para la película {0} (se esperaban 22243)'.format(_take_1[0]))\n",
    "Test.assertEquals(__builtin__.round(_take_1[2], 2), 3.21, \"Puntuación media incorecta para la película {0}. Se esperaba 3.21\".format(_take_1[0]))\n",
    "\n",
    "Test.assertTrue(_take_2[0] == 3 and _take_2[1] == 12735,\n",
    "                'Conteo de puntuaciones incorrecto para la película  {0} (expected 12735)'.format(_take_2[0]))\n",
    "Test.assertEquals(__builtin__.round(_take_2[2], 2), 3.15, \"Puntuación media incorecta para la película {0}. Se esperaba 3.15\".format(_take_2[0]))\n",
    "\n",
    "\n",
    "Test.assertEquals(movie_names_with_avg_ratings_df.count(), 26744,\n",
    "                  'movie_names_with_avg_ratings_df.count() incorrecto (se esperaban 26744)')\n",
    "movie_names_with_ratings_take_ordered = movie_names_with_avg_ratings_df.orderBy(['average', 'title']).take(3)\n",
    "result = [(r['average'], r['title'], r['count'], r['movieId']) for r in movie_names_with_ratings_take_ordered]\n",
    "Test.assertEquals(result,\n",
    "                  [(0.5, u'13 Fighting Men (1960)', 1, 109355),\n",
    "                   (0.5, u'20 Years After (2008)', 1, 131062),\n",
    "                   (0.5, u'3 Holiday Tails (Golden Christmas 2: The Second Tail, A) (2011)', 1, 111040)],\n",
    "                  'Las tres primeras Rows de movie_names_with_avg_ratings_df no son correctas')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1b) Películas con la puntuación más alta y al menos 500 puntuaciones recibidas\n",
    "\n",
    "Ahora que tenemos el DataFrame con las puntuaciones medias podemos usar Spark para obtener las 20 películas con la puntuación media más alta que tengan por lo menos 500 puntuaciones asignadas.\n",
    "\n",
    "Utilizar una única transformación para limiar el resultado de las películas a aquellas que han sido puntuadas como mínimo 500 veces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Películas con las puntuaciones más altas:\n",
      "+-------+-----+------------------+-------+--------------------------------+\n",
      "|movieId|count|average           |MovieID|title                           |\n",
      "+-------+-----+------------------+-------+--------------------------------+\n",
      "|3997   |2047 |2.0703468490473864|3997   |Dungeons & Dragons (2000)       |\n",
      "|1580   |35580|3.55831928049466  |1580   |Men in Black (a.k.a. MIB) (1997)|\n",
      "|3918   |1246 |2.918940609951846 |3918   |Hellbound: Hellraiser II (1988) |\n",
      "|2366   |6627 |3.5492681454655197|2366   |King Kong (1933)                |\n",
      "|3175   |13945|3.600717102904267 |3175   |Galaxy Quest (1999)             |\n",
      "|4519   |1936 |3.2463842975206614|4519   |Land Before Time, The (1988)    |\n",
      "|1591   |5255 |2.6201712654614653|1591   |Spawn (1997)                    |\n",
      "|471    |11268|3.6641817536386228|471    |Hudsucker Proxy, The (1994)     |\n",
      "|36525  |1169 |3.482891360136869 |36525  |Just Like Heaven (2005)         |\n",
      "|44022  |2465 |3.334077079107505 |44022  |Ice Age 2: The Meltdown (2006)  |\n",
      "|2866   |1407 |3.605188343994314 |2866   |Buddy Holly Story, The (1978)   |\n",
      "|1645   |11458|3.4787484726828417|1645   |Devil's Advocate, The (1997)    |\n",
      "|5803   |1046 |2.772944550669216 |5803   |I Spy (2002)                    |\n",
      "|54190  |1687 |3.6701244813278007|54190  |Across the Universe (2007)      |\n",
      "|1088   |11013|3.209207300463089 |1088   |Dirty Dancing (1987)            |\n",
      "|833    |1427 |2.725998598458304 |833    |High School High (1996)         |\n",
      "|8638   |3449 |3.9375181211945494|8638   |Before Sunset (2004)            |\n",
      "|1959   |5016 |3.628987240829346 |1959   |Out of Africa (1985)            |\n",
      "|1342   |3289 |2.949072666463971 |1342   |Candyman (1992)                 |\n",
      "|1238   |3194 |3.96665623043206  |1238   |Local Hero (1983)               |\n",
      "+-------+-----+------------------+-------+--------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_with_500_ratings_or_more = movie_names_with_avg_ratings_df.filter(movie_names_with_avg_ratings_df['count'] >= 500)                                                           \n",
    "print('Películas con las puntuaciones más altas:')\n",
    "movies_with_500_ratings_or_more.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertEquals(movies_with_500_ratings_or_more.count(), 4489,\n",
    "                  'movies_with_500_ratings_or_more.count() incorrecto. Se esperaban 4489.')\n",
    "top_20_results = [(r['average'], r['title'], r['count']) for r in movies_with_500_ratings_or_more.orderBy(desc('average')).take(20)]\n",
    "\n",
    "Test.assertEquals(top_20_results,\n",
    "                  [(4.446990499637029, u'Shawshank Redemption, The (1994)', 63366),\n",
    "                   (4.364732196832306, u'Godfather, The (1972)', 41355),\n",
    "                   (4.334372207803259, u'Usual Suspects, The (1995)', 47006),\n",
    "                   (4.310175010988133, u\"Schindler's List (1993)\", 50054),\n",
    "                   (4.275640557704942, u'Godfather: Part II, The (1974)', 27398),\n",
    "                   (4.2741796572216, u'Seven Samurai (Shichinin no samurai) (1954)', 11611),\n",
    "                   (4.271333600779414, u'Rear Window (1954)', 17449),\n",
    "                   (4.263182346109176, u'Band of Brothers (2001)', 4305),\n",
    "                   (4.258326830670664, u'Casablanca (1942)', 24349),\n",
    "                   (4.256934865900383, u'Sunset Blvd. (a.k.a. Sunset Boulevard) (1950)', 6525),\n",
    "                   (4.24807897901911, u\"One Flew Over the Cuckoo's Nest (1975)\", 29932),\n",
    "                   (4.247286821705426, u'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)', 23220),\n",
    "                   (4.246001523229246, u'Third Man, The (1949)', 6565),\n",
    "                   (4.235410064157069, u'City of God (Cidade de Deus) (2002)', 12937),\n",
    "                   (4.2347902097902095, u'Lives of Others, The (Das leben der Anderen) (2006)', 5720),\n",
    "                   (4.233538107122288, u'North by Northwest (1959)', 15627),\n",
    "                   (4.2326233183856505, u'Paths of Glory (1957)', 3568),\n",
    "                   (4.227123123722136, u'Fight Club (1999)', 40106),\n",
    "                   (4.224281931146873, u'Double Indemnity (1944)', 4909),\n",
    "                   (4.224137931034483, u'12 Angry Men (1957)', 12934)],\n",
    "                  'Top 20 de películas con 500 o más puntuaciones incorrecto')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Filtro colaborativo\n",
    "En esta parte vamos a aprender a usar MLlib para realizar recomendaciones personalizadas utilizando los datos sobre las puntuaciones de las películas.\n",
    "\n",
    "Para ello vamos a usar el método de Filtro Colaborativo. Este método trata de hacer predicciones automáticas (filtro) sobre los intereses de un usuario a partir de los gustos de otros muchos usuarios (colaborativo). La suposición sobre la que se realiza el filtro colaborativo es que si a una persona A tiene la misma opinión que una persona B en un tema, es más probable que A tenga la misma opinión que B en otro tema x diferente, respecto a que tenga la opinión sobre x de una persona elegida al azar. Más información: [1][collab], [2][collab2].\n",
    "\n",
    "Para la recomendación de películas, partimos de una matriz cuyas entradas son las puntuaciones dadas a las películas por los usuarios, donde cada columna representa a un usuario y cada fila representa a una película.\n",
    "\n",
    "Como todos los usuarios no han puntuado todas las películas, tenemos entradas de la matriz con valor desconocido, razón por la que necesitamos aplicar el filtro colaborativo. Para cada usuario, tenemos las puntuaciones para un pequeño subconjunto de películas. Con el filtro colaborativo la idea es aproximar las puntuaciones de la matriz factorizándola como el producto de dos matrices: una que describe las propiedades de cada usuario y otra que describe las de cada película.\n",
    "\n",
    "Vamos a tratar de seleccionar estas matrices de tal forma que el error para los pares de usuarios/películas que conocemos sea el mínimo. Para estre proósito usamos el método de [Alternating Least Squares][als]. Este algoritmo primero inicializa aleatoriamente la matriz de usuarios y trata de optimizar la matriz de películas. Luego, mantiene la matriz de películas constante y optimiza la de usuarios. Esta alternancia entre la optimización de ambas matrices es la razón por la que se denomina así el método.\n",
    "\n",
    "[als]: https://en.wikiversity.org/wiki/Least-Squares_Method\n",
    "[collab]: https://en.wikipedia.org/?title=Collaborative_filtering\n",
    "[collab2]: http://recommender-systems.org/collaborative-filtering/"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2a) Creación del conjunto de entrenamiento\n",
    "\n",
    "Antes de usar Machine Learning, tenemos que dividir el conjunto de `ratings_df` en tres partes:\n",
    "* Un conjunto de entrenamiento (DataFrame), que usaremos para entrenar los modelos\n",
    "* Un conjunto de validación(DataFrame), que usaremos para elegir el mejor modelo\n",
    "* Un conjunto de test (DataFrame), que usaremos para conocer el rendimiento del modelo final\n",
    "\n",
    "Para dividir el DataFrame en diferentes grupos podemos usar la transformación [randomSplit()](http://spark.apache.org/docs/2.0.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.randomSplit) . `randomSplit()` toma un vector con los porcentages de datos que irán a cada partición y una semilla y devuelve tantos DataFrames como elementos tiene el vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 12002851, validación: 4000457, test: 3996955\n",
      "\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|     29|   3.5|\n",
      "|     1|    112|   3.5|\n",
      "|     1|    151|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|     47|   3.5|\n",
      "|     1|    253|   4.0|\n",
      "|     1|    296|   4.0|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     1|      2|   3.5|\n",
      "|     1|     32|   3.5|\n",
      "|     1|     50|   3.5|\n",
      "+------+-------+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utilizaremos el 60% de los datos para entrenamiento, el 20% para validación y el 20% para test\n",
    "# Utilizar randomSplit\n",
    "seed = 1800009193\n",
    "(split_60_df, split_a_20_df, split_b_20_df) = ratings_df.randomSplit([0.6, 0.2, 0.2], seed)\n",
    "\n",
    "# Vamos a cachear los tres DataFrames ¡¡¡CUIDADO LABORATORIO!!!!!!\n",
    "training_df = split_60_df.cache()\n",
    "validation_df = split_a_20_df.cache()\n",
    "test_df = split_b_20_df.cache()\n",
    "\n",
    "print('Train: {0}, validación: {1}, test: {2}\\n'.format(\n",
    "      training_df.count(), validation_df.count(), test_df.count())\n",
    "    )\n",
    "\n",
    "training_df.show(3)\n",
    "validation_df.show(3)\n",
    "test_df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Si los primeros tres test fallan pero los números son similares, no hay problema\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "# TEST Creación del conjunto de entrenamiento (2a)\n",
    "print (\"Si los primeros tres test fallan pero los números son similares, no hay problema\")\n",
    "Test.assertEquals(training_df.count(), 12002851, \"Conteo de training_df incorrecto. Se esperaban 12002750\")\n",
    "Test.assertEquals(validation_df.count(), 4000457, \"Conteo de validation_df incorrecto. Se esperaban 3999777\")\n",
    "Test.assertEquals(test_df.count(), 3996955, \"Conteo de test_df incorrecto. Se esperaban 3997736\")\n",
    "\n",
    "Test.assertEquals(training_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 5952) & (ratings_df.rating == 5.0)).count(), 1)\n",
    "Test.assertEquals(training_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 1193) & (ratings_df.rating == 3.5)).count(), 1)\n",
    "Test.assertEquals(training_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 1196) & (ratings_df.rating == 4.5)).count(), 1)\n",
    "\n",
    "Test.assertEquals(validation_df.filter((ratings_df.userId == 1) & (ratings_df.movieId == 296) & (ratings_df.rating == 4.0)).count(), 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de dividir el DataFrame, el train debe tener unas 12 millones de instancias y la validación y el test unas 4 millones. (El número exacto de entradas puede variar ligeramente por la aleatoriedad de `randomSplit()`.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2b) Alternating Least Squares\n",
    "\n",
    "En esta parte vamos a usar la implementación del algoritmo en MLlib [ALS](http://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS). ALS toma un conjunto de entrenamiento (DatAFrame) y varios parámetros que controlan la creación del modelo. Para determinar los mejores valores para los parámetros utilizaremos ALS para entrenar varios modelos y elegiremos aquel con el mejor comportamiento para el resto de la práctica.\n",
    "\n",
    "Para determinar el mejor modelo usaremos la partición de validación de la siguiente forma:\n",
    "**NOTA: Idealmente, podríamos utilizar `CrossValidator` o `TrainValidationSplit`de MLlib para la estimación. Sin embargo tiene algunos problemas con ALS como explicamos después.**\n",
    "\n",
    "1. Seleccionamos un conjunto de parámetros para probar el modelo. El parámetro más importante en ALS es *rank*, que determina el número de columnas en la matriz de usuarios o el número de filas en la matriz de películas. En general, un rank menor conllevará un mayor error en training, pero un rank muy alto puede llevarnos a sobreentrenar y obtener malas predicciones en validación/test. Usaremos los valores de rank = {4, 8, 12} con el DataFrame `training_df`\n",
    "\n",
    "2. Establecemos los parámetros necesarios para ejecutar ALS:\n",
    "    * La columna \"User\" será la columna `userId` de nuestro DataFrame.\n",
    "    * La columna \"Item\" será la columna `movieId` de nuestro DataFrame.\n",
    "    * La columna \"Rating\" será la columna `rating` de nuestro DataFrame.\n",
    "    * La columna \"Prediction\" se llamará `prediction` en nuestro DataFrame generado.\n",
    "    * Utilizaremos el parámetro de regularización con valor 0.1 (este podría ser otro parámetro a ajustar como rank).\n",
    "\n",
    "**Nota**: Documentación de [ALS] [ALS](http://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS)\n",
    "\n",
    "\n",
    "3. Crearemos varios modelos usando [ALS.fit()](http://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.recommendation.ALS.fit), uno para cada valor de rank. Utilizar el conjunto de entrenamiento (`training_df`).\n",
    "\n",
    "4. Con cada modelo obtenido, usaremos el método `transform()` para obtener la predicción sobre el conjunto de validación  (`validation_df`) en un nuevo DataFrame con la predicción en una nueva columna llamada \"prediction\".\n",
    "\n",
    "5. Comprobaremos el error obtenido.\n",
    "\n",
    "6. Nos quedaremos con el modelo que obtenga el menor error en validación.\n",
    "\n",
    "#### ¿Por qué usar nuestra propia validación y no la de MLlib?\n",
    "\n",
    "Un tema importante del filtro colaborativo es como dar puntuaciones a los nuevos usuarios (usuarios que no han puesto ninguna puntuación). Algunos sistemas dan unas predicciones por defecto y otros no predicen nada para nuevos usuarios. Este segundo es el caso de Spark ALS, produce NaN's para las recomendaciones a usuarios nuevos. \n",
    "\n",
    "Sin entrar en mucho detalle, para usar  [CrossValidator](http://spark.apache.org/docs/2.0.2/api/python/pyspark.ml.html#pyspark.ml.tuning.CrossValidator) debemos usar un evaluador como RMSE que no soporta NaN's y a nada que haya un NaN el resultado serán NaN y la elección de parámetros no tendrá sentido. El problema es que al hacer el particionamiento puede haber usuarios sin puntuaciones en training, por lo que sus puntuaciones predichas en validación serán NaN.\n",
    "\n",
    "Este es un problema con diferentes soluciones. En nuestro caso, simplemente eliminaremos los NaNs antes de calcular el error cuadrático medio (RMSE), y esta es la razón por la que lo hacemos manualmente.\n",
    "\n",
    "**NOTA: el próximo código tardará un poco en ejecutarse**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Para el rank 4 el RMSE es 0.8226079963698706\n",
      "Para el rank 8 el RMSE es 0.8089623386670514\n",
      "Para el rank 12 el RMSE es 0.8066401456311423\n",
      "El mejor modelo ha sido entrenado con rank 12\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "\n",
    "# Inicializamos el Estimator ALS\n",
    "als = ALS()\n",
    "\n",
    "# Establecemos los parámetros para ALS\n",
    "# Establecer las columnas de usuario, item, rating y predicción, setUserCol, setItemCol, setRatingCol, setPredictionCol\n",
    "als.setUserCol(\"userId\").setItemCol(\"movieId\").setRatingCol(\"rating\").setPredictionCol(\"prediction\").setRegParam(0.1)\n",
    "\n",
    "# Importamos el Evaluator para el conjunto de validación\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Creamos un evaluator RMSE usando la etiqueta que es rating y la predicción que es prediction\n",
    "reg_eval = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "\n",
    "tolerance = 0.03\n",
    "ranks = [4, 8, 12]\n",
    "errors = [0, 0, 0]\n",
    "models = [0, 0, 0]\n",
    "err = 0\n",
    "min_error = float('inf')\n",
    "best_rank = -1\n",
    "\n",
    "for rank in ranks:\n",
    "    # Establecemos el valor de rank con setRank para ALS\n",
    "    als.setRank(rank)\n",
    "    \n",
    "    # Entrenamos el modelo con estos parámetros\n",
    "    model = als.fit(training_df)\n",
    "    \n",
    "    # Ejecutamos el modelo para predecir los valores usando transform() en validación (validation_df)\n",
    "    predict_df = model.transform(validation_df)\n",
    "\n",
    "    # Eliminamos los valores NaN\n",
    "    predicted_ratings_df = predict_df.na.drop(subset=[\"prediction\"])\n",
    "\n",
    "    # Ejecutamos el evaluador RMSE creado previamente, reg_eval.evaluate, sobre el DataFrame predicted_ratings_df\n",
    "    error = reg_eval.evaluate(predicted_ratings_df)\n",
    "    errors[err] = error\n",
    "    models[err] = model\n",
    "    print('Para el rank %s el RMSE es %s' % (rank, error))\n",
    "    \n",
    "    if error < min_error:\n",
    "        min_error = error\n",
    "        best_rank = err\n",
    "        \n",
    "    err += 1\n",
    "\n",
    "als.setRank(ranks[best_rank])\n",
    "print('El mejor modelo ha sido entrenado con rank %s' % ranks[best_rank])\n",
    "my_model = models[best_rank]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test failed. Valor no esperado para el mejor RMSE. Debía ser 0.82 (redondeado). Obtenido 0.81\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Valor no esperado para el mejor RMSE. Debía ser 0.82 (redondeado). Obtenido 0.81",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mTest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massertEquals\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__builtin__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.82\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mValor no esperado para el mejor RMSE. Debía ser 0.82 (redondeado). Obtenido \u001b[39;49m\u001b[38;5;132;43;01m{0}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m__builtin__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mround\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmin_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m Test\u001b[38;5;241m.\u001b[39massertEquals(ranks[best_rank], \u001b[38;5;241m8\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValor no esperado para el mejor rank. Debía ser 8. Obtenido \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(ranks[best_rank]))\n\u001b[0;32m      3\u001b[0m Test\u001b[38;5;241m.\u001b[39massertEqualsHashed(als\u001b[38;5;241m.\u001b[39mgetItemCol(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m18f0e2357f8829fe809b2d95bc1753000dd925a6\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumna de item en ALS incorrecta \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(als\u001b[38;5;241m.\u001b[39mgetItemCol()))\n",
      "File \u001b[1;32m~\\Downloads\\Practica3\\test_helper.py:39\u001b[0m, in \u001b[0;36mTest.assertEquals\u001b[1;34m(cls, var, val, msg)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21massertEquals\u001b[39m(\u001b[38;5;28mcls\u001b[39m, var, val, msg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m---> 39\u001b[0m   \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massertTrue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Downloads\\Practica3\\test_helper.py:30\u001b[0m, in \u001b[0;36mTest.assertTrue\u001b[1;34m(cls, result, msg)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     29\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 test failed. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m msg)\n\u001b[1;32m---> 30\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg)\n",
      "\u001b[1;31mException\u001b[0m: Valor no esperado para el mejor RMSE. Debía ser 0.82 (redondeado). Obtenido 0.81"
     ]
    }
   ],
   "source": [
    "Test.assertEquals(__builtin__.round(min_error, 2), 0.82, \"Valor no esperado para el mejor RMSE. Debía ser 0.82 (redondeado). Obtenido {0}\".format(__builtin__.round(min_error, 2)))\n",
    "Test.assertEquals(ranks[best_rank], 8, \"Valor no esperado para el mejor rank. Debía ser 8. Obtenido {0}\".format(ranks[best_rank]))\n",
    "Test.assertEqualsHashed(als.getItemCol(), \"18f0e2357f8829fe809b2d95bc1753000dd925a6\", \"Columna de item en ALS incorrecta {0}.\".format(als.getItemCol()))\n",
    "Test.assertEqualsHashed(als.getUserCol(), \"db36668fa9a19fde5c9676518f9e86c17cabf65a\", \"Columna de user en ALS incorrecta {0}.\".format(als.getUserCol()))\n",
    "Test.assertEqualsHashed(als.getRatingCol(), \"3c2d687ef032e625aa4a2b1cfca9751d2080322c\", \"Columna de rating en ALS incorrecta {0}.\".format(als.getRatingCol()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2c) Testeando el modelo\n",
    "\n",
    "Para saber lo bueno que es realmente el modelo obtenido debemos utilizar el conjunto de test (`test_df`), que no ha sido utilizado ni para el entrenamiento ni para la elección de parámetros `test_df` dataset. Utilizaremos el modelo obtenido con el mejor rank (`best_rank`) almacenado en `my_model`para realizar las predicciones sobre el conjunto de test y obtendremos el error sobre este conjunto usando la raíz error cuadrático medio RMSE.\n",
    "\n",
    "Debes seguir los siguientes pasos:\n",
    "* Utiliza el método `transform()` del modelo `my_model` para predecir las puntuaciones en el conjunto de `test_df`. Obtendremos un nuevo DataFrame `predict_df`.\n",
    "* Filtramos los valores NaN obtenidos en la predicción. Utilizar el código incluido.\n",
    "* Usar el evaluador de RMSE `reg_eval` para obtener el error en test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo ha obtenido un RMSE en test de 0.8074452041743768\n"
     ]
    }
   ],
   "source": [
    "# Predecir los valores para test_df\n",
    "predict_df = my_model.transform(test_df)\n",
    "\n",
    "# Eliminamos los valores NaN\n",
    "predicted_test_df = predict_df.na.drop(subset=[\"prediction\"])\n",
    "\n",
    "# Ejecutamos el evaluador RMSE, reg_eval, sobre predicted_test_df\n",
    "test_RMSE = reg_eval.evaluate(predicted_test_df)\n",
    "print('El modelo ha obtenido un RMSE en test de {0}'.format(test_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertTrue(__builtin__.abs(test_RMSE - 0.809624038485) < tolerance, 'incorrect test_RMSE: {0:.11f}'.format(test_RMSE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2d) Comparando el modelo obtenido \n",
    "\n",
    "Atendiendo solo al RMSE obtenido es difícil saber si el modelo es de calidad o no. Sin embargo, podemos comparar este error frente a lo que sería predecir para todas las películas y usuarios la media de todas las puntuaciones en el entrenamiento. Es evidente que nuestro modelo debe comportarse mejor que esta predicción \"tonta\".\n",
    "\n",
    "Pasos a seguir:\n",
    "* Usar el DataFrame `training_df` para calcular la media de todas las puntuaciones (usar agg o groupBy() + avg).\n",
    "* Utilizar la puntuación media junto con el DataFrame `test_df` para crear otro DataFrame (`test_for_avg_df`) con una columna `prediction` con el valor de puntuación medio para todas las filas. **Nota**: Utilizar la función `lit()` para crear la columna con dicho valor. Utiliza la transformación `withColumn`.\n",
    "* Utiliza el evaluador `reg_eval` para obtener el error sobre el nuevo DataFrame `test_for_avg_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor medio de las puntuaciones en el conjunto de entrenamiento es 3.5255293513182826\n",
      "El RMSE de la predicción constante para todos es 1.0517429715171944\n"
     ]
    }
   ],
   "source": [
    "# Calcula la media de todas las puntuaciones en training_df\n",
    "avg_rating_df = training_df.agg(avg('rating').alias('avg_rating'))\n",
    "\n",
    "# Extrae el valor medio de las puntuaciones (fila 0, columna 0)\n",
    "training_avg_rating = avg_rating_df.first()['avg_rating']\n",
    "print('El valor medio de las puntuaciones en el conjunto de entrenamiento es {0}'.format(training_avg_rating))\n",
    "\n",
    "# Añade una columna con el valor medio de las puntuaciones\n",
    "test_for_avg_df = test_df.withColumn('prediction', lit(training_avg_rating))\n",
    "\n",
    "# Ejecuta el evaluador RMSE, reg_eval, sobre el DataFrame test_for_avg_df\n",
    "test_avg_RMSE = reg_eval.evaluate(test_for_avg_df)\n",
    "print(\"El RMSE de la predicción constante para todos es {0}\".format(test_avg_RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 test passed.\n",
      "1 test passed.\n"
     ]
    }
   ],
   "source": [
    "Test.assertTrue(__builtin__.abs(training_avg_rating - 3.52578917331) < 0.001,\n",
    "                'Valor incorrecto de training_avg_rating (expected 3.52578917331): {0:.11f}'.format(training_avg_rating))\n",
    "Test.assertTrue(__builtin__.abs(test_avg_RMSE - 1.05190953037) < 0.001,\n",
    "                'Valor incorrecto de test_avg_RMSE (expected 1.0519743756): {0:.11f}'.format(test_avg_RMSE))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Ya sabemos cómo predecir puntuaciones para las películas!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Predicciones para ti\n",
    "En esta última parte del ejercicio vamos a predecir las películas que habría que recomendarte a ti mismo. Para ello, primero necesitamos saber tus preferencias.\n",
    "\n",
    "Vamos a crear un DataFrame con tus preferencias denominado `ratings_df`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3a) Tus preferencias**\n",
    "\n",
    "Para ayudarte de la hora de establecer tus preferencias, a continuación puedes obtener una lista con los nombres y códigos de las 50 películas con mejor puntuación del DataFrame `movies_with_500_ratings_or_more`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Películas mejor puntuadas:\n",
      "(ID de la película, número de puntuaciones, puntuación media, título de la película)\n",
      "+-------+-----+------------------+-------+--------------------+\n",
      "|movieId|count|           average|MovieID|               title|\n",
      "+-------+-----+------------------+-------+--------------------+\n",
      "|    318|63366| 4.446990499637029|    318|Shawshank Redempt...|\n",
      "|    858|41355| 4.364732196832306|    858|Godfather, The (1...|\n",
      "|     50|47006| 4.334372207803259|     50|Usual Suspects, T...|\n",
      "|    527|50054| 4.310175010988133|    527|Schindler's List ...|\n",
      "|   1221|27398| 4.275640557704942|   1221|Godfather: Part I...|\n",
      "|   2019|11611|   4.2741796572216|   2019|Seven Samurai (Sh...|\n",
      "|    904|17449| 4.271333600779414|    904|  Rear Window (1954)|\n",
      "|   7502| 4305| 4.263182346109176|   7502|Band of Brothers ...|\n",
      "|    912|24349| 4.258326830670664|    912|   Casablanca (1942)|\n",
      "|    922| 6525| 4.256934865900383|    922|Sunset Blvd. (a.k...|\n",
      "|   1193|29932|  4.24807897901911|   1193|One Flew Over the...|\n",
      "|    750|23220| 4.247286821705426|    750|Dr. Strangelove o...|\n",
      "|   1212| 6565| 4.246001523229246|   1212|Third Man, The (1...|\n",
      "|   6016|12937| 4.235410064157069|   6016|City of God (Cida...|\n",
      "|  44555| 5720|4.2347902097902095|  44555|Lives of Others, ...|\n",
      "|    908|15627| 4.233538107122288|    908|North by Northwes...|\n",
      "|   1178| 3568|4.2326233183856505|   1178|Paths of Glory (1...|\n",
      "|   2959|40106| 4.227123123722136|   2959|   Fight Club (1999)|\n",
      "|   3435| 4909| 4.224281931146873|   3435|Double Indemnity ...|\n",
      "|   1203|12934| 4.224137931034483|   1203| 12 Angry Men (1957)|\n",
      "|  77658|  936|4.2206196581196584|  77658|       Cosmos (1980)|\n",
      "|  58559|20438| 4.220129171151776|  58559|Dark Knight, The ...|\n",
      "|   1198|43295| 4.219009123455364|   1198|Raiders of the Lo...|\n",
      "|   3030| 3559| 4.211716774374825|   3030|      Yojimbo (1961)|\n",
      "|   1284| 5529| 4.207361186471333|   1284|Big Sleep, The (1...|\n",
      "|    926| 4826|4.2041027766266055|    926|All About Eve (1950)|\n",
      "|   5618|13466| 4.203809594534383|   5618|Spirited Away (Se...|\n",
      "|   1252|15310| 4.199673416067929|   1252|    Chinatown (1974)|\n",
      "|    930| 4932|   4.1977899432279|    930|    Notorious (1946)|\n",
      "|   4973|24349|  4.19707174832642|   4973|Amelie (Fabuleux ...|\n",
      "|   1260| 4232| 4.193171077504726|   1260|            M (1931)|\n",
      "|    260|54502| 4.190671901948552|    260|Star Wars: Episod...|\n",
      "|   1207|14769| 4.188943056401923|   1207|To Kill a Mocking...|\n",
      "|   1196|45313| 4.188202061218635|   1196|Star Wars: Episod...|\n",
      "|    913|12144| 4.187211791831357|    913|Maltese Falcon, T...|\n",
      "|   2571|51334| 4.187185880702848|   2571|  Matrix, The (1999)|\n",
      "|    950| 3358|    4.184187016081|    950|Thin Man, The (1934)|\n",
      "|   1213|26406| 4.183632507763387|   1213|   Goodfellas (1990)|\n",
      "|   1248| 4718| 4.183022467147096|   1248|Touch of Evil (1958)|\n",
      "|  94466|  582|  4.18298969072165|  94466| Black Mirror (2011)|\n",
      "|   1148|15022| 4.181067767274664|   1148|Wallace & Gromit:...|\n",
      "|   4226|30443|4.1785467923660615|   4226|      Memento (2000)|\n",
      "|    593|63299|  4.17705650958151|    593|Silence of the La...|\n",
      "|   1197|32586|4.1767323390413065|   1197|Princess Bride, T...|\n",
      "|   5291| 3712| 4.176724137931035|   5291|Rashomon (Rashômo...|\n",
      "|   2324|18156| 4.175837188808107|   2324|Life Is Beautiful...|\n",
      "|    296|67310| 4.174231169217055|    296| Pulp Fiction (1994)|\n",
      "|   1136|33024| 4.174146075581396|   1136|Monty Python and ...|\n",
      "|   3307| 2593| 4.174122637871192|   3307|  City Lights (1931)|\n",
      "|   1217| 4824| 4.173611111111111|   1217|          Ran (1985)|\n",
      "+-------+-----+------------------+-------+--------------------+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Películas mejor puntuadas:')\n",
    "print('(ID de la película, número de puntuaciones, puntuación media, título de la película)')\n",
    "movies_with_500_ratings_or_more.orderBy(movies_with_500_ratings_or_more['average'].desc()).show(50)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ID de usuario 0 no está asignado, por lo que lo usaremos para tus puntuaciones. La variable `my_user_ID` tiene el valor 0 asignado. Utilizándolo, crea un nuevo DataFrame llamado `my_ratings_df` con tus puntuaciones para al menos 10 películas. Cada entrada tiene que estar en el siguiente formato:  `(my_user_id, movieID, rating)`.  \n",
    "\n",
    "Como en el dataset original, las puntuaciones deben estar entre 1 y 5 (incluidos ambos). Si no has visto al menos 10 de esas películas puedes mostrar más cambiando el parámetro pasado a `take()` hasta que encuentres 10 películas que hayas visto (o sino puedes establecer la puntuación que crees que tendrían las películas para ti)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mis puntuaciones son:\n",
      "+------+-------+------+\n",
      "|userId|movieId|rating|\n",
      "+------+-------+------+\n",
      "|     0|    260|   5.0|\n",
      "|     0|   1196|   5.0|\n",
      "|     0|   1210|   4.5|\n",
      "|     0|    296|   4.5|\n",
      "|     0|    318|   5.0|\n",
      "|     0|    356|   4.5|\n",
      "|     0|    110|   4.0|\n",
      "|     0|      1|   4.0|\n",
      "|     0|    589|   4.5|\n",
      "|     0|    593|   4.5|\n",
      "+------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "my_user_id = 0\n",
    "\n",
    "# Ten en cuenta que el ID de las películas es el último número en cada línea\n",
    "# Un error común es utilizar el número de puntuación como ID de película, ¡ten cuidado!\n",
    "my_rated_movies = [ \n",
    "    (my_user_id, 260, 5.0),   # Star Wars: Episode IV - A New Hope (1977)\n",
    "    (my_user_id, 1196, 5.0),  # Star Wars: Episode V - The Empire Strikes Back (1980)\n",
    "    (my_user_id, 1210, 4.5),  # Star Wars: Episode VI - Return of the Jedi (1983)\n",
    "    (my_user_id, 296, 4.5),   # Pulp Fiction (1994)\n",
    "    (my_user_id, 318, 5.0),   # The Shawshank Redemption (1994)\n",
    "    (my_user_id, 356, 4.5),   # Forrest Gump (1994)\n",
    "    (my_user_id, 110, 4.0),   # Braveheart (1995)\n",
    "    (my_user_id, 1, 4.0),     # Toy Story (1995)\n",
    "    (my_user_id, 589, 4.5),   # Terminator 2: Judgment Day (1991)\n",
    "    (my_user_id, 593, 4.5),   # The Silence of the Lambs (1991)\n",
    "    (my_user_id, 527, 4.5),   # Schindler's List (1993)\n",
    "    (my_user_id, 480, 4.0),   # Jurassic Park (1993)\n",
    "]\n",
    "\n",
    "# El formato de cada línea debe ser (my_user_id, movie ID, tu puntuación)\n",
    "# Por ejemplo, parala película \"Star Wars: Episode IV - A New Hope (1977)\" cinco estrellas, debería añadir la siguiente línea\n",
    "#   (my_user_id, 260, 5)\n",
    "my_ratings_df = spark.createDataFrame(my_rated_movies, ratings_df_schema)\n",
    "\n",
    "print('Mis puntuaciones son:')\n",
    "my_ratings_df.show(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3b) Unión de tus puntuaciones con el conjunto de entrenamiento\n",
    "\n",
    "Para poder obtener nuevas predicciones para ti, debemos incluir las puntuaciones previas en el conjunto de entrenamiento. Utiliza para ello la transformación [unionAll()](http://spark.apache.org/docs/2.0.2/api/python/pyspark.sql.html#pyspark.sql.DataFrame.unionAll); utiliza `unionAll()` para crear un nuevo conjunto de entrenamiento con tus puntuaciones (`my_ratings_df`) y el conjunto de train `training_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El conjunto de entrenamiento tiene ahora 12 más filas que el original\n"
     ]
    }
   ],
   "source": [
    "# Utiliza unionAll() para unir my_ratings_df con training_df\n",
    "training_with_my_ratings_df = training_df.unionAll(my_ratings_df)\n",
    "\n",
    "print ('El conjunto de entrenamiento tiene ahora %s más filas que el original' %\n",
    "       (training_with_my_ratings_df.count() - training_df.count()))\n",
    "assert (training_with_my_ratings_df.count() - training_df.count()) == my_ratings_df.count()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3c) Entrenamiento del modelo con tus puntuaciones\n",
    "\n",
    "Ahora vamos a entrenar un nuevo modelo considerando tus puntuaciones junto con las que ya teníamos en el training original. Utilizaremos los mismos parámetros que en las partes (2b) y (2c). **Recuerda incluir TODOS los parámetros**.\n",
    "\n",
    "**NOTA:** Esta ejecución tardará un poco, paciencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establece los parámetros para ALS: \n",
    "#    regularización, columna de items, usuarios y puntuaciones y el rank (el mejor obtenido)\n",
    "als.setRegParam(0.1) \\\n",
    "    .setItemCol(\"movieId\") \\\n",
    "    .setUserCol(\"userId\") \\\n",
    "    .setRatingCol(\"rating\") \\\n",
    "    .setPredictionCol(\"prediction\") \\\n",
    "    .setRank(ranks[best_rank])\n",
    "\n",
    "# Entrenar el modelo con los parámetros establecidos, es decir, utilizar fit() con el nuevo training set: training_with_my_ratings_df\n",
    "my_ratings_model = als.fit(training_with_my_ratings_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3d) Comprobar el error RMSE del nuevo modelo\n",
    "\n",
    "Vamos a calcular el RMSE obtenido para el nuevo modelo para el conjunto de test.\n",
    "* Utiliza el modelo (`transform()`) para obtener las predicciones para el conjunto de test `test_df`\n",
    "* Después, utiliza `reg_eval` (el evaluador) para calcular el RMSE (método `evaluate`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo tiene un RMSE en el conjunto de test de 0.808036131118998\n"
     ]
    }
   ],
   "source": [
    "my_predict_df = my_ratings_model.transform(test_df)\n",
    "\n",
    "# Filtramos los valores NaN\n",
    "predicted_test_my_ratings_df = my_predict_df.na.drop(subset=[\"prediction\"])\n",
    "\n",
    "# Obtener el error usando reg_eval y predicted_test_my_ratings_df\n",
    "test_RMSE_my_ratings = reg_eval.evaluate(predicted_test_my_ratings_df)\n",
    "print('El modelo tiene un RMSE en el conjunto de test de {0}'.format(test_RMSE_my_ratings))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3e) Predicción de nuevas puntuaciones para ti\n",
    "\n",
    "Hasta ahora lo único que hemos hecho es calcular el error del modelo. Ahora, lo que vamos a hacer es predecir que puntuaciones le habrías dado a las películas que todavía no has puntuado.\n",
    "\n",
    "Debemos seguir los siguientes pasos:\n",
    "* Filtrar las películas que has puntuado manualmente. Utilizaremos la variable `my_rated_movie_ids` para guardar los IDs de las películas puntuadas y almacenaremos las no puntuadas en un DataFrame `not_rated_df`.\n",
    "\n",
    "   **Nota**: La función [Column.isin()](http://spark.apache.org/docs/2.0.2/api/python/pyspark.sql.html#pyspark.sql.Column.isin)\n",
    "   y el operador lógico \"no\" `~` pueden ayudar en esta operación. Aquí viene un ejemplo con `isin()`:\n",
    "\n",
    "```\n",
    "    > df1 = spark.createDataFrame([(\"Jim\", 10), (\"Julie\", 9), (\"Abdul\", 20), (\"Mireille\", 19)], [\"name\", \"age\"])\n",
    "    > df1.show()\n",
    "    +--------+---+\n",
    "    |    name|age|\n",
    "    +--------+---+\n",
    "    |     Jim| 10|\n",
    "    |   Julie|  9|\n",
    "    |   Abdul| 20|\n",
    "    |Mireille| 19|\n",
    "    +--------+---+\n",
    "\n",
    "    > names_to_delete = [\"Julie\", \"Abdul\"] # esto es  una lita de Python\n",
    "    > df2 = df1.filter(~ df1[\"name\"].isin(names_to_delete)) # \"NOT IN\"\n",
    "    > df2.show()\n",
    "    +--------+---+\n",
    "    |    name|age|\n",
    "    +--------+---+\n",
    "    |     Jim| 10|\n",
    "    |Mireille| 19|\n",
    "    +--------+---+\n",
    "```\n",
    "\n",
    "* Transformar `not_rated_df` en `my_unrated_movies_df` siguiendo los siguientes pasos:\n",
    "    - renombrar la columna \"ID\" por \"movieId\" utilizando `withColumnRenamed()`\n",
    "    - añadir una columna \"userId\" con el valor que tiene la variable `my_user_id` definida anteriormente. Utiliza para ello el método `withColumn()` junto con la función `lit()` para añadir una columna con el mismo valor en todas las filas.\n",
    "\n",
    "* Crear el DataFrame `predicted_ratings_df` aplicando el modelo aprendindo `my_ratings_model` al DataFrame `my_unrated_movies_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una lista con los IDs de las películas ya puntuadas\n",
    "my_rated_movie_ids = [x[1] for x in my_rated_movies] # simplemente cogemos el segundo valor de las tuplas\n",
    "\n",
    "# Filtrar las películas ya puntuadas - utiliza my_rated_movie_ids con el método isin sobre la columna \"ID\" - ver ejemplo anterior\n",
    "not_rated_df = movies_df.filter(~ movies_df[\"ID\"].isin(my_rated_movie_ids))\n",
    "\n",
    "# Renombrar la columna \"ID\" por \"movieId\" y añadir la columna \"userId\" con my_user_id usando la función lit()\n",
    "my_unrated_movies_df = not_rated_df.withColumnRenamed(\"ID\", \"movieId\") \\\n",
    "                                   .withColumn(\"userId\", lit(my_user_id))\n",
    "\n",
    "# Utilizar el modelo my_ratings_model para predecir las puntuaciones dadas a las películas que no han sido puntuadas manualmente\n",
    "raw_predicted_ratings_df = my_ratings_model.transform(my_unrated_movies_df)\n",
    "\n",
    "# Filtramos los NaN\n",
    "predicted_ratings_df = raw_predicted_ratings_df.na.drop(subset=[\"prediction\"]) \\\n",
    "                                                 .select(\"userId\", \"movieId\", \"prediction\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3f) Predicción final de las películas recomendadas para ti\n",
    "\n",
    "Ya hemos predecido las puntuaciones, ahora podemos mostrar las 25 películas con mejores puntuaciones que serían las recomendadas.\n",
    "\n",
    "Pasos a seguir:\n",
    "* Unir el DataFrame `predicted_ratings_df` con `movie_names_with_avg_ratings_df` para obtener el conteo de puntuaciones para cada película\n",
    "* Ordenar el DataFrame resultante (`predicted_with_counts_df`) por la puntuación (descendente) y eliminar las películas con 75 puntuaciones o menos\n",
    "* Imprimir el top 25 de las películas restantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necesario para que funcione el join según la versión de spark\n",
    "spark.conf.set(\"spark.sql.crossJoin.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El top 25 de películas recomendadas para ti es (películas con al menos 75 puntuaciones):\n",
      "+-------+------+----------+-----+--------------------+\n",
      "|movieId|userId|prediction|count|               title|\n",
      "+-------+------+----------+-----+--------------------+\n",
      "|    858|     0| 4.6244497|41355|Godfather, The (1...|\n",
      "|     50|     0|  4.604972|47006|Usual Suspects, T...|\n",
      "|   1198|     0|  4.594491|43295|Raiders of the Lo...|\n",
      "|   7153|     0| 4.5918255|31577|Lord of the Rings...|\n",
      "|   7502|     0| 4.5908937| 4305|Band of Brothers ...|\n",
      "|   4993|     0|  4.583934|37553|Lord of the Rings...|\n",
      "|  93040|     0| 4.5575852|  256|Civil War, The (1...|\n",
      "|   5952|     0|  4.552036|33947|Lord of the Rings...|\n",
      "|   2571|     0|  4.544142|51334|  Matrix, The (1999)|\n",
      "|   1221|     0| 4.4995623|27398|Godfather: Part I...|\n",
      "|  58559|     0| 4.4789295|20438|Dark Knight, The ...|\n",
      "|  77658|     0| 4.4544177|  936|       Cosmos (1980)|\n",
      "|   1136|     0|  4.443885|33024|Monty Python and ...|\n",
      "| 108583|     0|  4.409071|  230|Fawlty Towers (19...|\n",
      "|   1197|     0|  4.405489|32586|Princess Bride, T...|\n",
      "|   2028|     0| 4.3895807|37110|Saving Private Ry...|\n",
      "|   2019|     0| 4.3886943|11611|Seven Samurai (Sh...|\n",
      "|   2959|     0| 4.3860745|40106|   Fight Club (1999)|\n",
      "|   1148|     0|  4.381444|15022|Wallace & Gromit:...|\n",
      "|   1203|     0|  4.381307|12934| 12 Angry Men (1957)|\n",
      "+-------+------+----------+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Utiliza un join() para unir predicted_ratings_df con movie_names_with_avg_ratings_df (campo movieId)\n",
    "predicted_with_counts_df = predicted_ratings_df.join(\n",
    "    movie_names_with_avg_ratings_df.select('movieId', 'count', 'title'),\n",
    "    on='movieId',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "# Utiliza un filter para filtrar las películas con al menos de 75 puntuaciones, aprovecha para ordenar el DataFrame por la columna prediction de manera descendente\n",
    "predicted_highest_rated_movies_df = (\n",
    "    predicted_with_counts_df\n",
    "    .filter(col('count') >= 75)\n",
    "    .orderBy(desc('prediction'))\n",
    "    .limit(25)\n",
    ")\n",
    "\n",
    "# Mostrar el top25 de las películas con show()\n",
    "print ('El top 25 de películas recomendadas para ti es (películas con al menos 75 puntuaciones):')\n",
    "predicted_highest_rated_movies_df.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "name": "cs110_lab2_als_prediction",
  "notebookId": 3391522265018542
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
